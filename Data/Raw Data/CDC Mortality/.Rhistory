#     lab_data <- lab_data %>% filter(!(ResultValueNBR == 9999999))
#
#     #Map to CCCTN Shock Labs
#     lab_data <- lab_data[lab_data$ComponentID %in% lab_maps$ComponentID,]
#     lab_data <- merge(lab_data,lab_maps[,c("ComponentID","Include","Lab","CCCTNShock")],all.x=T,all.y=F,by = "ComponentID")
#
#     #Standardize time field
#     lab_data$ResultDTS <- as.POSIXct(lab_data$ResultDTS,tz="EST")
#     lab_data$SpecimenTakenTimeDTS <- as.POSIXct(lab_data$SpecimenTakenTimeDTS,tz="EST")
#
#     #Save All Lab Data
#     compile_all_labs[[i]] <- lab_data
#
#     #Extract Echo Data
#     echo_data <- lab_data %>% filter(CCCTNShock == "ECHO")
#
#     #Narrow results to time of Shock (T-72 to T + 72)
#     lab_data$timefromshock <- as.period(lab_data$SpecimenTakenTimeDTS - shockonset,"hours")
#     lab_data <- lab_data[(lab_data$SpecimenTakenTimeDTS >= shockonset - hours(72) & lab_data$SpecimenTakenTimeDTS <= shockonset + hours(72)),]
#
#     #Keep dose closest to onset of shock, + 24 hours, and +48 hours
#     shock_labs_0 <- lab_data %>% filter(CCCTNShock == TRUE) %>% group_by(Lab) %>% slice(which.min(abs(period_to_seconds(timefromshock))))
#     shock_labs_24 <- lab_data %>% filter(CCCTNShock == TRUE) %>% group_by(Lab) %>%  slice(which.min(abs(period_to_seconds(timefromshock-hours(24)))))
#     shock_labs_48 <- lab_data %>% filter(CCCTNShock == TRUE) %>% group_by(Lab) %>%  slice(which.min(abs(period_to_seconds(timefromshock-hours(48)))))
#
#     #RPDR Formatting
#     shock_labs_0 <- merge(shock_labs_0,redcap_labs,all.x=T,all.y=F,by.x="Lab",by.y="Lab")
#     shock_labs_24 <- merge(shock_labs_24,redcap_labs,all.x=T,all.y=F,by.x="Lab",by.y="Lab")
#     shock_labs_48 <- merge(shock_labs_48,redcap_labs,all.x=T,all.y=F,by.x="Lab",by.y="Lab")
#
#     shock_labs_0 <- shock_labs_0 %>% arrange(Order) %>% select(redcapMRN,MRN,Lab,ResultTXT, ResultValueNBR, ReferenceRangeUnitCD, SpecimenTakenTimeDTS, ResultDTS, BaseNM, ComponentCommonNM, timefromshock)
#     shock_labs_24 <- shock_labs_24 %>% arrange(Order) %>% select(redcapMRN,MRN,Lab,ResultTXT, ResultValueNBR, ReferenceRangeUnitCD, SpecimenTakenTimeDTS, ResultDTS, BaseNM, ComponentCommonNM, timefromshock)
#     shock_labs_48 <- shock_labs_48 %>% arrange(Order) %>% select(redcapMRN,MRN,Lab,ResultTXT, ResultValueNBR, ReferenceRangeUnitCD, SpecimenTakenTimeDTS, ResultDTS, BaseNM, ComponentCommonNM, timefromshock)
#
#     #Recent TTE
#     echo_data$timefromshock <- as.period(echo_data$ResultDTS - shockonset,"hours")
#     recent_tte <- echo_data %>% slice_min(abs(period_to_seconds(timefromshock)),with_ties = T)
#
#     #Output
#     compile_shock_labs_0[[i]] <- shock_labs_0
#     compile_shock_labs_24[[i]] <- shock_labs_24
#     compile_shock_labs_48[[i]] <- shock_labs_48
#     compile_all_tte[[i]] <- echo_data
#     compile_recent_tte[[i]] <- recent_tte
#
#   },
#   error = function(e) {
#     message(paste("Lab data processing error with MRN: ", mrns$mrn[i]))
#     message("Original error message:")
#     # Choose a return value in case of error
#     return(NA)
#   },
#   warning = function(w) {
#     message(paste("Lab data processing with MRN: ", mrns$mrn[i]))
#     message("Original warning message:")
#     # Choose a return value in case of warning
#     return(NULL)
#   }
# )
setTxtProgressBar(pb, i)
}
#Libraries
library(tidyverse)
#SetWD (need to be on VPN/MBG Intranet)
setwd("/Volumes/My Documents/EDW")
#Load Data
data <- read.csv("VIS_Output.csv")
data <- data[,-1]
#Expand timefromshock to seconds
data$timefromshock <- data$timefromshock
#Expand VIS score to each minute to calculate a geometric average, set a window period
window_number <- 6
minutes_sequence <- seq(0,24*60,by = 1)
vis <- data %>% complete(MRN, timefromshock = minutes_sequence) %>% arrange(MRN,timefromshock) %>%
fill(VIS,.direction="down") %>% replace_na(list(VIS=0)) %>% mutate(window = floor(timefromshock/(1440/window_number))+1)
#filter VIS to 24 hour period
vis <- vis %>% filter(timefromshock >= 0 & timefromshock < 24*60)
#Create Average VIS Per Window
windows <- vis %>% group_by(MRN,window) %>%
summarise(window_VIS = mean(VIS))
#Calculate Mean and SD VIS per patient, then standardize avg_VIS
windows <- windows %>% group_by(MRN) %>%
mutate(MRN_mean = mean(window_VIS),
MRN_sd = sd(window_VIS)) %>% ungroup() %>%
mutate(window_VIS_std = (window_VIS - MRN_mean)/MRN_sd)
#Replace NaN values with 0
windows <- windows %>% mutate(window_VIS_std = replace_na(window_VIS_std,0))
#Create Wide DF
window_vis_df <- windows %>% select(MRN,window,window_VIS) %>% pivot_wider(names_from = window, values_from = window_VIS)
window_vis_std_df <- windows %>% select(MRN,window,window_VIS_std) %>% pivot_wider(names_from = window, values_from = window_VIS_std)
names(window_vis_std_df) <- paste(names(window_vis_std_df),"_v",sep="")
df <- cbind(window_vis_df,window_vis_std_df) %>% select(-"MRN_v")
#K-Means Cluster
set.seed(317)
k = 4
scale_df <- scale(df)
kclusters <- kmeans(scale_df,k)
df$clusters <- factor(kclusters$cluster)
cluster_df <- df %>% select(-contains("_v")) %>% pivot_longer(!c(MRN,clusters),names_to = "window",values_to = "VIS") %>%
group_by(clusters,window) %>% summarise(
mean_VIS = mean(VIS))
cluster_df %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 4-Hour Windows",
x = "Window (4 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5))
cluster_df %>% filter(clusters != 2) %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 4-Hour Windows",
subtitle = "Excluding High VIS Cluster",
x = "Window (4 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
#Load Data
data <- read.csv("VIS_Output.csv")
data <- data[,-1]
#Expand timefromshock to seconds
data$timefromshock <- data$timefromshock
#Expand VIS score to each minute to calculate a geometric average, set a window period
window_number <- 12
minutes_sequence <- seq(0,24*60,by = 1)
vis <- data %>% complete(MRN, timefromshock = minutes_sequence) %>% arrange(MRN,timefromshock) %>%
fill(VIS,.direction="down") %>% replace_na(list(VIS=0)) %>% mutate(window = floor(timefromshock/(1440/window_number))+1)
#filter VIS to 24 hour period
vis <- vis %>% filter(timefromshock >= 0 & timefromshock < 24*60)
#Create Average VIS Per Window
windows <- vis %>% group_by(MRN,window) %>%
summarise(window_VIS = mean(VIS))
#Calculate Mean and SD VIS per patient, then standardize avg_VIS
windows <- windows %>% group_by(MRN) %>%
mutate(MRN_mean = mean(window_VIS),
MRN_sd = sd(window_VIS)) %>% ungroup() %>%
mutate(window_VIS_std = (window_VIS - MRN_mean)/MRN_sd)
#Replace NaN values with 0
windows <- windows %>% mutate(window_VIS_std = replace_na(window_VIS_std,0))
#Create Wide DF
window_vis_df <- windows %>% select(MRN,window,window_VIS) %>% pivot_wider(names_from = window, values_from = window_VIS)
window_vis_std_df <- windows %>% select(MRN,window,window_VIS_std) %>% pivot_wider(names_from = window, values_from = window_VIS_std)
names(window_vis_std_df) <- paste(names(window_vis_std_df),"_v",sep="")
df <- cbind(window_vis_df,window_vis_std_df) %>% select(-"MRN_v")
#K-Means Cluster
set.seed(317)
k = 4
scale_df <- scale(df)
kclusters <- kmeans(scale_df,k)
df$clusters <- factor(kclusters$cluster)
cluster_df <- df %>% select(-contains("_v")) %>% pivot_longer(!c(MRN,clusters),names_to = "window",values_to = "VIS") %>%
group_by(clusters,window) %>% summarise(
mean_VIS = mean(VIS))
cluster_df %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 4-Hour Windows",
x = "Window (2 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5))
cluster_df %>% filter(clusters != 2) %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 2-Hour Windows",
subtitle = "Excluding High VIS Cluster",
x = "Window (4 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
cluster_df %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 2-Hour Windows",
x = "Window (2 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5))
cluster_df %>% filter(clusters != 2) %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 2-Hour Windows",
subtitle = "Excluding High VIS Cluster",
x = "Window (2 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
#Load Data
data <- read.csv("VIS_Output.csv")
data <- data[,-1]
#Expand timefromshock to seconds
data$timefromshock <- data$timefromshock
#Expand VIS score to each minute to calculate a geometric average, set a window period
window_number <- 4
minutes_sequence <- seq(0,24*60,by = 1)
vis <- data %>% complete(MRN, timefromshock = minutes_sequence) %>% arrange(MRN,timefromshock) %>%
fill(VIS,.direction="down") %>% replace_na(list(VIS=0)) %>% mutate(window = floor(timefromshock/(1440/window_number))+1)
#filter VIS to 24 hour period
vis <- vis %>% filter(timefromshock >= 0 & timefromshock < 24*60)
#Create Average VIS Per Window
windows <- vis %>% group_by(MRN,window) %>%
summarise(window_VIS = mean(VIS))
#Calculate Mean and SD VIS per patient, then standardize avg_VIS
windows <- windows %>% group_by(MRN) %>%
mutate(MRN_mean = mean(window_VIS),
MRN_sd = sd(window_VIS)) %>% ungroup() %>%
mutate(window_VIS_std = (window_VIS - MRN_mean)/MRN_sd)
#Replace NaN values with 0
windows <- windows %>% mutate(window_VIS_std = replace_na(window_VIS_std,0))
#Create Wide DF
window_vis_df <- windows %>% select(MRN,window,window_VIS) %>% pivot_wider(names_from = window, values_from = window_VIS)
window_vis_std_df <- windows %>% select(MRN,window,window_VIS_std) %>% pivot_wider(names_from = window, values_from = window_VIS_std)
names(window_vis_std_df) <- paste(names(window_vis_std_df),"_v",sep="")
df <- cbind(window_vis_df,window_vis_std_df) %>% select(-"MRN_v")
#K-Means Cluster
set.seed(317)
k = 4
scale_df <- scale(df)
kclusters <- kmeans(scale_df,k)
df$clusters <- factor(kclusters$cluster)
cluster_df <- df %>% select(-contains("_v")) %>% pivot_longer(!c(MRN,clusters),names_to = "window",values_to = "VIS") %>%
group_by(clusters,window) %>% summarise(
mean_VIS = mean(VIS))
cluster_df %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 6-Hour Windows",
x = "Window (6 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5))
cluster_df %>% filter(clusters != 2) %>% ggplot(aes(x=as.numeric(window),y=mean_VIS,group=clusters,color=clusters)) +
geom_point() +
geom_line() +
theme_classic() +
labs(title = "Mean VIS by Cluster during 6-Hour Windows",
subtitle = "Excluding High VIS Cluster",
x = "Window (6 Hours)",
y = "Mean VIS") +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
#Google Trends
install.packages("gtrendsR")
library(gtrendsR)
data("categories")
View(categories)
# Define the search term (example with one term for simplicity)
search_terms <- c("Exercise")
# Define the years
years <- 2004:2020
# Define the geographical location (US at country level)
geo_location <- "US"
# Initialize a list to store the results
trends_list <- list()
# Loop through each search term
for (term in search_terms) {
cat("Retrieving data for:", term, "\n")
# Initialize a list for this term's yearly data
term_data <- list()
# Loop through each year
for (year in years) {
cat(" Year:", year, "\n")
time_period <- paste(year, "-01-01 ", year, "-12-31", sep = "")
# Attempt to retrieve data
# Note: Error handling is not included in this example
trend <- gtrends(keyword = term, time = time_period, geo = geo_location)
term_data[[as.character(year)]] <- trend
# Pause to avoid hitting rate limits (Google does not officially support rapid automated queries)
Sys.sleep(5)
}
trends_list[[term]] <- term_data
}
time_period <- paste(year, "-01-01 ", year, "-12-31", sep = "")
# Attempt to retrieve data
# Note: Error handling is not included in this example
trend <- gtrends(keyword = term, time = time_period, geo = geo_location)
setwd("~/Documents/GitHub/BMI706/Data/Raw Data/CDC Mortality")
#Read Data
# List all CSV files in the directory
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
read_txt(file_path) %>%
mutate(FileName = file_name)
#Libraries
library(tidyverse)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
read_txt(file_path) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
#Read Data
# List all CSV files in the directory
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
#Read Data
# List all CSV files in the directory
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
#Read Data
# List all CSV files in the directory
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
#Read Data
# List all CSV files in the directory
path <- getwd()
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
read_txt(file_path) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
read_tsv(file_path) %>%
mutate(FileName = file_name)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
read_tsv(file_path) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
problems()
test <- read_tsv("all_cause.txt")
problems(test)
test <- read_delim("all_cause.txt",delim="\t")
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t", escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
read_delim
?read_delim
file_names <- list.files(path, pattern = "*.txt", full.names = TRUE)
test <- read_delim("all_cause.txt",delim="\t")
# Function to read CSV and add a column with the file name
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",
col_types = cols(escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
}
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = cols(escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
}
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = "-ffnfffffffnnnnnnn",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = "-ffnfffffffnnnnnnn",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(FileName = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
View(combined_df)
hist(combined_df$`% of Total Deaths`)
length(combined_df$Deaths[is.na(combined_df$Deaths)])
9778/length(combined_df)
9778/length(combined_df$Deaths)
hist(combined_df$Deaths)
hist(combined_df$Deaths[combined_df$Deaths<=1000])
hist(combined_df$Deaths[combined_df$Deaths<=500])
hist(combined_df$Deaths[combined_df$Deaths<=100])
hist(combined_df$Deaths[combined_df$Deaths<=300])
hist(combined_df$Deaths[combined_df$Deaths<=30])
# Optional: Write the combined dataframe to a new CSV file
write_csv(combined_df, "merged_data.csv")
# Impute missing values
averages <- data %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year,FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
# Impute missing values
averages <- data %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
#Libraries
library(tidyverse)
# Impute missing values
averages <- data %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
combined_df$FileName <- as.factor(combined_df$FileName)
# Impute missing values
averages <- data %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
library(dplyr)
# Impute missing values
averages <- data %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
# Impute missing values
averages <- data %>%
dplyr::group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
# Impute missing values
averages <- data %>%
dplyr::group_by(State) %>% # %>% `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
# Impute missing values
averages <- combined_df %>%
group_by(State, `Ten-Year Age Groups`, Gender, Race, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
View(averages)
View(combined_df)
# Impute missing values
averages <- combined_df %>%
group_by(State, `Ten-Year Age Groups`, Gender, Year, FileName) %>%
summarize(AvgDeaths = mean(Deaths, na.rm = TRUE),
AvgPop = mean(Population,na.rm = TRUE))
View(combined_df)
#Replace Na in death column with 0
combined_df <- combined_df %>% mutate(Deaths = replace_na(Deaths,0))
# Optional: Write the combined dataframe to a new CSV file
write_csv(combined_df, "merged_data.csv")
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = "-ffnfffffffnnnnnnn",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate('Cause of Death' = file_name)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = "-ffnfffffffnnnnnnn",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate('Cause of Death' = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
combined_df$'Cause of Death' <- as.factor(combined_df$'Cause of Death')
#Replace Na in death column with 0
combined_df <- combined_df %>% mutate(Deaths = replace_na(Deaths,0))
#Clean Up Cause of Death Columns
combined_df <- combined_df %>% mutate('Cause of Death' = str_replace('Cause of Death',"all_case_2","all_cause"))
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
#Replace Na in death column with 0
combined_df <- combined_df %>% mutate(Deaths = replace_na(Deaths,0))
#Clean Up Cause of Death Columns
combined_df <- combined_df %>% mutate('Cause of Death' = str_replace('Cause of Death',"all_case_2","all_cause"))
combined_df$'Cause of Death' <- as.factor(combined_df$'Cause of Death')
View(combined_df)
# Function to read CSV and add a column with the file name
read_and_add_filename <- function(file_path) {
file_name <- tools::file_path_sans_ext(basename(file_path))
# Use read_delim with tab as the delimiter
read_delim(file_path, delim = "\t",col_types = "-ffnfffffffnnnnnnn",escape_double = FALSE, col_names = TRUE, trim_ws = TRUE) %>%
mutate(cause_of_death = file_name)
}
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
#Replace Na in death column with 0
combined_df <- combined_df %>% mutate(Deaths = replace_na(Deaths,0))
#Clean Up Cause of Death Columns
combined_df <- combined_df %>% mutate(cause_of_death = str_replace(cause_of_death,"all_case_2","all_cause"))
View(combined_df)
combined_df$cause_of_death <- as.factor(combined_df$cause_of_death)
levels(combined_df$cause_of_death)
# Read all files, add FileName column, and combine into one dataframe
combined_df <- map_df(file_names, read_and_add_filename)
#Replace Na in death column with 0
combined_df <- combined_df %>% mutate(Deaths = replace_na(Deaths,0))
#Clean Up Cause of Death Columns
combined_df <- combined_df %>% mutate(cause_of_death = str_replace(cause_of_death,"all_cause_2","all_cause"))
combined_df$cause_of_death <- as.factor(combined_df$cause_of_death)
levels(combined_df$cause_of_death)
# Optional: Write the combined dataframe to a new CSV file
write_csv(combined_df, "merged_data.csv")
unique(combined_df$cause_of_death)
combined_df <- combined_df %>%
mutate(cause_of_death = str_replace_all(cause_of_death, "_", " "),  # Replace underscores with spaces
cause_of_death = str_to_title(cause_of_death))  # Convert to title case
# Optional: Write the combined dataframe to a new CSV file
write_csv(combined_df, "mortality_data.csv")
